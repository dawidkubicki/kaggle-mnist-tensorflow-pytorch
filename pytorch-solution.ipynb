{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and normalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_data[\"label\"])\n",
    "x_train = np.array(train_data.drop(columns=[\"label\"]))\n",
    "x_train = x_train / 255.0\n",
    "x_test = np.array(test_data) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[1].reshape(28,28))\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(42000, 28, 28).astype('float32')\n",
    "x_test = x_test.reshape(28000, 28, 28).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_tensor = torch.tensor(x_train).cuda()\n",
    "train_labels_tensor = torch.tensor(y_train).cuda()\n",
    "\n",
    "test_images_tensor = torch.tensor(x_test).cuda()\n",
    "\n",
    "train_images_tensor = train_images_tensor.view(-1, 1, 28, 28).float()\n",
    "test_images_tensor = test_images_tensor.view(-1, 1, 28, 28).float()\n",
    "\n",
    "train_tensor = TensorDataset(train_images_tensor, train_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_tensor, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_images_tensor, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        hidden1 = 512\n",
    "        hidden2 = 512\n",
    "        self.fc1 = nn.Linear(28*28, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = Net()\n",
    "print(model)\n",
    "model.to(torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "n_epochs = 10\n",
    "# valid_loss_min = np.Inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-9032f764fc95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# model.eval()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "\n",
    "model.train() \n",
    "for data, target in train_loader:\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item() * data.size(0)\n",
    "\n",
    "# model.eval() \n",
    "# for data, target in valid_loader:\n",
    "#     output = model(data)\n",
    "#     loss = criterion(output, target)\n",
    "#     valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "train_loss = train_loss / len(train_loader.sampler)\n",
    "#valid_loss = valid_loss / len(valid_loader.sampler)\n",
    "\n",
    "print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "    epoch + 1,\n",
    "    train_loss\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
